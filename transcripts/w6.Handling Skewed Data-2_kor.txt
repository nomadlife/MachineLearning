Trading off precision and recall

0:00
마지막 비디오에서는 왜곡 된 상수가있는 분류 문제에 대한 평가 척도로 정밀도와 리콜에 대해 이야기했습니다. 많은 애플리케이션에서 정밀도와 리콜 간의 절충점을 어떻게 든 제어하려고합니다. 이를 수행하는 방법을 알려주고 학습 알고리즘에 대한 평가 척도로 정밀도와 리콜을 사용하는 더욱 효과적인 방법을 보여줍니다.
0:28
여기에 이전 비디오의 정밀도와 리콜에 대한 정의가 있습니다.
0:35
암 분류 예를 계속하겠습니다. 환자가 암에 걸렸 으면 y가 1이고 그렇지 않으면 y가 0입니다. 그리고 우리가 0과 1 사이의 확률을 출력하는 로지스틱 회귀 분류기에서 훈련했다고 가정 해 봅시다. 그래서 평소와 같이 h (x)가 0.5보다 크거나 같으면 1을 예측하고 y는 1과 같습니다. 그리고 가설이 0.5보다 작은 값을 출력하면 0을 예측합니다. 그리고이 분류 기준은 정확성에 대한 가치와 회상에 대한 가치를 우리에게 줄 수 있습니다.
1:10
그러나 지금 우리가 정말로 확신 할 때만 환자가 암에 걸렸다 고 예측하고 싶다고 가정 해 봅시다. 환자에게 가서 암에 걸렸다 고 말하면 환자에게 큰 충격을 줄 것입니다. 우리가주는 것은 심각하게 나쁜 소식이며, 그들은 꽤 고통스러운 치료 과정을 거치게 될 것입니다. 그래서 우리는 누군가 자신에게 매우 확신이있을 때만 암이 있다고 생각한다고 말하고 싶습니다. 이를 수행하는 한 가지 방법은 알고리즘을 수정하는 것입니다. 따라서이 임계 값을 0.5로 설정하는 대신 h (x)가 0.7 이상인 경우에만 y가 1과 같을 것이라고 예측할 수 있습니다. 따라서 이것은 암에 걸릴 확률이 70 % 이상이라고 생각하는 경우에만 누군가에게 암이 있다고 말합니다.
2:00
그리고, 만약 당신이 이것을한다면, 당신은 자신감이 더 커질 때만 암을 가지고 있다는 것을 예측할 수 있습니다. 그래서 더 높은 정밀도를 갖는 분류 자로 끝납니다. 우리는 환자가 암에 걸렸다 고 생각하기 때문에 모든 환자가 암에 걸릴 것이라고 생각하기 때문에 암 환자라고 생각합니다. 따라서 우리가 꽤 자신감이있는 경우에만 그러한 예측을하기 때문에 실제로 암으로 의심되는 환자의 비율이 더 높습니다.
2:34
반대로이 분류 기준은 예측을 할 것이기 때문에 더 적은 회수에서 y = 1을 예측할 것이기 때문에 더 낮은 회수율을 갖습니다. 자, 이것도 더 받아 들일 수 있습니다. 임계 값을 0.7로 설정하는 대신 0.9로 설정할 수 있습니다. 이제 우리는 환자가 암에 걸렸다는 확신이 90 % 이상인 경우에만 y = 1을 예측합니다. 그리고 그 환자의 상당 부분이 암이라고 판명 될 것입니다. 그리고 이것은 더 정밀도가 높고 recall이 낮은 precision classifier가 될 것입니다. 왜냐하면 우리는 이들 환자가 암에 걸렸음을 정확하게 감지하기를 원하기 때문입니다. 이제 다른 예를 생각해보십시오. 우리가 암의 실제 사례를 너무 많이 놓치지 않기를 원한다고 가정 할 때, false negative를 피하고자합니다. 특히 환자가 실제로 암에 걸렸지 만 암에 걸렸다고 말해주는데 실패하면, 이것은 매우 나쁜결과입니다. 환자에게 암이 없다고 말하면 치료를받지 않을 것이기 때문입니다. 암에 걸렸다는 사실이 밝혀 지지만 암에 걸렸다 고 말하면 실패하면, 암 치료를받지 못할 수도 있습니다. 그리고 그것은 우리가 암에 걸리지 않는다고 말했기 때문에 죽기 때문에 정말 나쁜 결과가 될 것입니다. 그들은 치료를받지 못했지만 암에 걸렸다는 것이 밝혀졌습니다. 그래서, 의심 스러울 때 y = 1이라고 예측하고 싶다고 가정 해보십시오. 따라서 의심 스러울 때, 우리는 암에 걸렸다는 것을 예측하기를 원하고, 그래서 적어도 더 주의깊게 관찰하고, 암이 생겼을때 치료할 수 있습니다.
4:04
이 경우 더 높은 확률 임계 값을 설정하는 대신 이값을 더 낮은 값으로 설정할 수 있습니다. 그래서 한 0.3정도? 그렇게 함으로써 우리는 암을 가질 확률이 30 % 이상이라고 생각한다면 우리는 더 보수적 인 편이 좋고 필요하다면 암을 가지고 치료를받을 수 있다고 말합니다.
4:31
그리고이 경우 우리가 가진 것은 더 높은 recall classifier일 것입니다. 왜냐하면 실제로 암을 가진 모든 환자의 더 높은 부분을 정확하게 표시하기 때문입니다. 그러나 우리는 더 낮은 정확도로 끝날 것입니다. 왜냐하면 우리가 암이라고 말한 환자 중 많은 부분이 암에 걸리지 않았다고 판명될 것이기 때문입니다.

5:00
그런데 학자와 마찬가지로, 다른 학생들과 이야기 할 때, 저는 이전에 들었습니다. 제 학생들 중 몇몇은 제가 두 가지 방법으로 이야기 할 수있는 방법이라고 말합니다. 왜 우리는 더 높은 정확도 또는 더 높은 리콜을 원할 수 있으며 이야기는 실제로 두 가지 방식으로 작동하는 것처럼 보입니다. 그러나 알고리즘의 세부 사항이 사실이고 좀 더 일반적인 원칙은 당신이 더 높은 정밀도 - 낮은 리콜 또는 더 높은 리콜 - 낮은 정밀도를 원 하든지간에 원하는 위치에 의존하기를 바랍니다. h (x)가 어떤 임계 값보다 클 때 y = 1을 예측할 수 있습니다. 그리고 일반적으로 대부분의 분류 자에게는 정밀도와 리콜 사이의 상충 관계가있을 것입니다. 여기에 참여하는이 임계 값을 다양 화하면 실제로 정밀도와 리콜을 막는 곡선을 그릴 수 있습니다. 여기 값이 임계 값의 매우 높은 값에 해당합니다. 임계 값이 0.99 일 수 있습니다. 따라서 우리가 99 % 이상의 확신을 가지고있는 경우에만 y = 1을 예측하고, 적어도 99 %의 확률로 예측하십시오. 그래서 이것은 고정밀도, 상대적으로 낮은 리콜이 될 것입니다. 여기 아래의 점은 훨씬 낮은, 아마도 0.01과 같은 임계 값의 값에 해당합니다. 즉, 의심 할 여지가 없으면 y = 1을 예측하고, 그렇게하면 훨씬 낮은 정밀도로 끝납니다 , 더 높은 회수 분류기. 그리고 임계 값을 변경할 때 원하는 경우 실제로 분류 자의 곡선을 추적하여 정밀 호출을 위해 얻을 수있는 다양한 값의 범위를 볼 수 있습니다. 그런데 정밀 리콜 곡선은 여러 가지 모양처럼 보일 수 있습니다. 때로는 이렇게 보일 때가 있는데 때로는 그렇게 보일 것입니다. 이제 분류기의 세부 사항에 따라 정밀도 - 회수 곡선에 대해 가능한 여러 가지 모양이 있습니다. 그래서 이것은 또 다른 흥미로운 질문을 제기합니다. 즉,이 임계 값을 자동으로 선택하는 방법이 있습니까? 또는 더 일반적으로 몇 가지 알고리즘이나 알고리즘에 대한 몇 가지 아이디어가 있다면 다양한 정확도 리콜 수치를 어떻게 비교합니까? 구체적으로 세 가지 학습 알고리즘이 있다고 가정 해 보겠습니다. 그래서 실제로, 이것들은 세 가지 다른 학습 알고리즘입니다. 아마도 이것들은 동일한 알고리즘이지만 임계 값에 대해 다른 값을 가질 수 있습니다. 어떻게 이러한 알고리즘 중 가장 적합한 알고리즘을 결정할 수 있습니까? 이전에 이야기했던 것 중 하나는 단일 실수 평가 메트릭의 중요성입니다. 그리고 그것은 당신의 분급자가 얼마나 잘하는지 알려주는 숫자를 갖는 아이디어입니다. 그러나 정밀 리콜 측정 기준으로 전환하면 실제로이를 잃어 버렸습니다. 이제 두 개의 실수가 있습니다. 그래서 우리는 종종 알고리즘 1과 알고리즘 2를 비교하려고 할 때, 0.5의 정밀도와 0.4의 리콜이 0.7의 정밀도보다 좋거나 나쁘지 않은지와 같은 상황에 직면하게됩니다. 그리고 0.1의 리콜? 그리고 새로운 알고리즘을 시도 할 때마다 앉아서 생각할 필요가 있다면, 아마도 0.5 / 0.4가 0.7 / 0.1보다 좋을 수도 있고 아닐 수도 있습니다. 결국 앉아서 이러한 결정을 내리고 생각하게되면 결국 의사 결정 프로세스가 느려지므로 변경 사항이 알고리즘에 통합되는 데 유용합니다.
8:23
대조적으로, 우리에게 알고리즘 1 또는 알고리즘 2가 더 나은 숫자를 나타내는 것과 같은 단일 실수 평가 메트릭이있는 경우 어떤 알고리즘을 사용할지 훨씬 더 빨리 결정할 수 있습니다. 알고리즘에 대해 고려할 수있는 다양한 변경 사항을보다 신속하게 평가하는 데에도 도움이됩니다. 그렇다면 우리는 어떻게 단일 실수 평가 메트릭을 얻을 수 있습니까?
8:47
당신이 시도해 볼 수있는 하나의 자연스러운 것은 평균 정밀도와 리콜을 보는 것입니다. 따라서 P와 R을 사용하여 정밀도와 리콜을 나타낼 수 있습니다. 평균값을 계산하고 가장 높은 평균값을 가진 분류기를 살펴 보는 것입니다.

9시
그러나 이것은 좋은 해결책이 아닙니다. 이전 예와 비슷하게 y = 1을 항상 예측하는 분류기가있는 경우, 그렇게하면 매우 높은 회수율을 얻을 수 있습니다 , 그러나 당신은 매우 낮은 정밀도의 값으로 끝납니다. 반대로, y가 거의 같지 않다고 예측하는 분류기가있는 경우 거의 y = 1로 예측합니다. 이는 이전 y의 표기법을 사용하여 매우 높은 임계 값을 설정하는 것과 같습니다. 그러면 매우 낮은 정확률로 매우 정확하게 리콜 할 수 있습니다. 따라서 매우 높은 임계 값 또는 매우 낮은 임계 값의 두 극한값 중 어느 것도 좋은 분류 기준을 제공하지 못합니다. 우리가 인식하는 방식은 매우 낮은 정확도 또는 매우 낮은 리콜로 끝나는 것을 보는 것입니다. 그리고이 예제에서 (P + R) / 2의 평균을 취하면 알고리즘 3에서 평균이 가장 높습니다. y = 1을 항상 예측하여 이러한 종류의 성능을 얻을 수는 있지만 실제로는 그렇지 않습니다. 아주 좋은 분류 자야, 그렇지? 항상 유용한 y = 1을 예측할 수 있지만, y = 1이면 인쇄됩니다. 그래서 알고리즘 1이나 알고리즘 2는 알고리즘 3보다 더 유용합니다. 그러나이 예에서 알고리즘 3은 알고리즘 1과 알고리즘 2보다 정밀도 리콜 평균 값이 높습니다. 따라서 우리는 일반적으로이 평균 정밀도를 생각하고 우리의 학습 알고리즘을 평가하는 좋은 방법입니다.
10:38
대조적으로 정밀도와 리콜을 결합하는 다른 방법이 있습니다. 이를 F 점수라고하며이 공식을 사용합니다. 그리고이 예에서 F 점수가 있습니다. 그래서 우리는이 F 점수에서 알 수 있습니다. 알고리즘 1은 F 점수가 가장 높고, 알고리즘 2가 두 번째로 높고, 알고리즘 3이 가장 낮습니다. 그래서 우리가 F 스코어에 가면 알고리즘 1을 선택합니다.
11:04
F1 점수라고도하는 F 점수는 보통 여기에있는 F1 점수로 작성되지만, 종종 사람들은 F 점수를 말하고 두 용어 중 하나를 사용합니다. 정밀도와 리콜 평균을 취하는 것과 조금 비슷하지만 정확도와 리콜의 가치가 낮습니다. 어느 것이 든간에 더 높은 가중치를 부여합니다. 그래서 여기에서 분자에서 F 스코어가 정밀도와 리콜의 산물을 차지한다는 것을 알 수 있습니다. 따라서 정밀도가 0이거나 리콜이 0이면 F 점수는 0이됩니다. 따라서이 점은 정밀도와 리콜을 결합하지만 F 점수가 크면 정밀도와 리콜 모두가 높습니다. 꽤 커야. 정밀도와 리콜을 빗질하기위한 가능한 여러 가지 공식이 있다고 말해야합니다. 이 F 점수 공식은 훨씬 더 많은 가능성 중 하나 일뿐입니다. 그러나 역사적으로나 전통적으로 이것은 기계 학습에서 사람들이 사용하는 것입니다. F score라는 용어는 아무 의미도 없으므로 F 점수 또는 F1 점수라는 이유에 대해 걱정하지 마십시오.
12:09
그러나 이것은 일반적으로 정확도가 0이거나 리콜이 0 일 때 매우 낮은 F 점수를 가지므로 높은 F 점수를 가지기 때문에 정확도 또는 리콜이 필요합니다 하나. 그리고 구체적으로 P = 0 또는 R = 0이면 F 점수 = 0이됩니다. 완벽한 F 점수이기 때문에 정밀도가 1이고 리콜이 1이면 F 점수가 주어집니다.
12:43
그것은 2 배의 1 배 1과 같기 때문에 완벽한 정밀도와 완벽한 리콜을 가지고 있다면 F 점수는 1이됩니다. 0과 1 사이의 중간 값은 대개 다른 분류 기준의 합리적인 순위 순서를 제공합니다.

(QUIZ)

13:00
그래서 이 비디오에서 정밀도와 리콜 사이의 거래에 대한 개념과 y = 1 또는 y = 0을 예측할지 여부를 결정하는 데 사용되는 임계 값을 어떻게 다르게 할 수 있는지에 대해 이야기했습니다. 따라서 우리가 y = 1을 예측하기 전에 적어도 70 %의 자신감을 갖거나 90 %의 자신감을 가져야하는지, 아니면 무엇이든지간에 필요하다고 말하는 임계 값입니다. 또한 임계 값을 변경하여 정밀도와 리콜간에 트레이드 오프를 제어 할 수 있습니다. 우리는 정밀도와 리콜을 취하는 F 점수에 대해서도 이야기했고, 다시 한 번 실수 평가 메트릭을 제공합니다. 그리고 실제로 y = 1과 y = 0을 결정하기 위해 임계 값을 자동으로 설정하는 것이 목표 인 경우이를 수행하는 합리적인 방법 중 하나는 다양한 임계 값 범위를 시도하는 것입니다. 따라서 임계 값의 범위를 시도하고 상호 유효성 검사 세트에서 이러한 다양한 임계 값을 평가 한 다음 교차 유효성 검사 [INAUDIBLE]에서 가장 높은 F 점수를 제공하는 임계 값의 값을 선택하십시오. 그리고 이것은 분류기에 대한 임계 값을 자동으로 선택하는 매우 합리적인 방법입니다.
