0:00
이전 비디오에서는 오류 분석과 오류 측정법의 중요성에 대해 이야기했습니다. 즉, 학습 알고리즘에 대한 실제 평가 기준 하나를 사용하여 얼마나 효과적인지 알려주는 것입니다.
0:14
평가 및 오류 측정 기준의 맥락에서 학습 알고리즘에 적합한 오류 측정 기준 또는 평가 척도를 제시하는 것이 특히 까다로운 경우가 하나 있습니다. 그 경우는 비뚤어진 클래스라고하는 것의 경우입니다. 그게 무슨 뜻인지 말해 줄께.

0:36
우리가 암 환자의 특징을 가지고있는 암 분류 문제를 생각해보고 암이 있는지 여부를 결정하고 싶습니다. 이것은 이전에 우리가 가지고 있었던 악성 대 양성 종양 분류 예와 같습니다.
0:51
환자가 암에 걸렸을 때 y가 1이고 그렇지 않은 경우 y가 0이라고 가정 해 봅시다. 진행 분류자를 훈련했고 테스트 집합에서 분류자를 테스트하고 1 % 오류가 발생했다고 가정 해 봅시다. 99 % 정확한 진단을 내리고 있습니다. 정말 인상적인 결과 인 것 같습니다. 우리는 정확한 99 %의 시간입니다.

1:12
그러나 이제는 우리의 훈련 테스트 세트에있는 환자의 0.5 %만이 실제로 암을 가지고 있음을 발견했다고 가정 해 봅시다. 따라서 우리 선별 과정을 거친 환자 중 절반만이 암에 걸립니다.
1:26
이 경우 1 % 오류가 더 이상 인상적으로 보이지 않습니다.
1:31
특히 여기에 코드가 있습니다. 여기에 실제로는 피쳐 x의 입력을 받아 들여 무시하는 비 학습 코드 조각이 있습니다. 단지 y = 0으로 설정하고 항상 예측합니다. 아무도 암을 가지지 않으며이 알고리즘은 실제로 0.5 %의 오차를 갖습니다. 그래서 이것은 지금 우리가 얻었던 1 % 오류보다 훨씬 낫습니다. 그리고 이것은 당신이 알고있는 학습 알고리즘이 아닙니다. 단지 y가 항상 0이라고 예측하고 있습니다.

1:57
따라서 긍정적 인 것과 부정적인 것의 비율이 두 극단의 어느 한쪽에 매우 근접한 경우의 설정으로,이 경우 긍정적 인 사례의 수는 음의 사례의 수보다 훨씬 적습니다. 왜냐하면 y는 매우 드물게 하나이므로, 이것이 우리가 왜곡 된 수업의 경우라고 부르는 것입니다.
2:20
한 클래스의 예제가 다른 클래스의 예제보다 훨씬 많습니다. y를 0으로 항상 예측하거나 y를 1로 예측하면 알고리즘은 꽤 잘할 수 있습니다. 따라서 분류 오차 또는 분류 정확도를 평가 척도로 사용하는 문제는 다음과 같습니다.
2:40
99.2 %의 정확도를 얻는 하나의 합류 알고리즘이 있다고 가정 해 보겠습니다.
2:46
그래서, 그것은 0.8 % 오류입니다. 알고리즘을 변경하고 이제 99.5 %의 정확도를 얻고 있다고 가정 해 보겠습니다.
2:59
0.5 % 오류입니다.
3:04
알고리즘에 대한 개선인가 아닌가? 하나의 실수 평가 메트릭에 대한 좋은 점 중 하나는 알고리즘에 대한 좋은 변경이 필요한지 여부를 신속하게 결정하는 데 도움이된다는 것입니다. 
3:21
99.2 %의 정확도에서 99.5 %의 정확도로 이동합니다., 우리는 단지 유용한 것을 했습니까? 아니면 단지 y가 0과 더 자주 같다고 예측하는 코드로 바꾸 었습니까? 따라서 클래스를 매우 비뚤어지게 만들면 분류 정확도를 사용하는 것이 훨씬 어려워집니다. 분류 정확도가 매우 높거나 오류가 매우 낮을 수 있기 때문에 분류 기준의 정확도를 높이는 것이 더 어려워집니다. 항상 0이면 좋은 분류 자처럼 보이지 않습니다.

3:53
하지만 y가 0 일 때 더 자주 예측하면 오류를 0.5 % 정도까지 낮출 수 있습니다. 우리가 그런 왜곡 된 클래스에 직면했을 때, 우리는 다른 에러 메트릭이나 다른 평가 메트릭을 제시하려고합니다. 이러한 평가 척도 중 하나가 정밀 리콜이라고하는 것입니다.



4:15
그것이 무엇인지 설명해 드리겠습니다.
4:17
우리가 테스트 세트에서 분류자를 평가한다고 가정 해 봅시다. 테스트 세트의 예제에서는 실제
4:25
테스트 세트에서 그 예제의 클래스는 바이너리 분류 문제가 있다면, 하나 또는 0이 될 것입니다.
4:33
우리의 학습 알고리즘은 클래스의 가치를 예측하고 학습 알고리즘이 테스트 세트의 각 예제에 대한 값을 예측하고 예측 된 값도 1 또는 0이 될 것입니다.
4:50
그래서 실제 클래스가 무엇이고 예상 클래스가 무엇인지에 따라이 엔트리들로 가득 찬 것에 따라 다음과 같이 두 개씩 두 개의 테이블을 그려 보도록하겠습니다. 실제 클래스가 하나이고 예상 클래스가 하나 인 예가 있으면 호출됩니다.
5:07
우리의 알고리즘이 그것이 긍정적이고 실제적으로 예제가 긍정적이라고 예측한다는 것을 의미하는 진정한 긍정적 인 예입니다. 우리의 학습 알고리즘이 무언가가 음수이고 클래스가 0이라고 예측하고 실제 클래스도 클래스 0이라면 그 값을 참값이라 부릅니다. 우리는 0을 예측했으며 실제로 0입니다.
5:27
다른 두 개의 상자를 찾으려면, 우리의 학습 알고리즘이 클래스가 하나라고 예측하지만
5:34
실제 클래스가 0이면 거짓 긍정 (false positive)이라고합니다.
5:39
즉 환자가하지 않으면 환자 알고리즘이 실제로 취소됩니다.
5:44
그리고 마지막으로, 마지막 상자는 0입니다. 우리의 알고리즘은 0을 예측했기 때문에 위양성이라고 부릅니다. 그러나 실제 클래스는 1입니다.
5:57
그래서 우리는 실제 클래스가 무엇이고 예측 클래스가 무엇인지에 따라이 두 종류의 두 테이블을가집니다.

6:07
여기 알고리즘의 성능을 평가하는 다른 방법이 있습니다. 두 숫자를 계산할 것입니다. 첫 번째는 정밀도라고 불리는데,
6:17
우리가 암에 걸렸다 고 예측 한 모든 환자들 중
6:20
실제로 암이있는 비율은 어느 정도입니까?

6:24
그래서 이것을 적어 보겠습니다. 분류 자의 정밀도는 실제 positive의 수를 우리가 positive로 예측한 총수로 나눕니다.

6:39
우리가 그 환자들에게 갔던 모든 환자들에 대해 우리는 그들에게 "당신은 암에 걸린 것 같아요."라고 말했습니다. 모든 환자 중에서 실제로 어느 정도의 비율의 암이 있습니까? 그래서 그것을 정밀도라고합니다. 그리고 이것을 쓰는 또 다른 방법은 참 긍정 일 것이고 그 다음에 분모에는 예측 된 포지티브의 수가 있습니다. 그러면 표의 첫 번째 행에있는 항목의 합계가됩니다. 진정한 긍정으로 나눌 수있는 진정한 긍정 일 것입니다. POS로 양수를 생략 한 다음 잘못된 양성을 표시하고 다시 POS를 사용하여 양수를 약어로 표시합니다.
7시 20 분
그래서 이것이 정밀도라고 불리우며, 정밀도가 높다는 것을 알 수 있습니다. 즉, 우리가 간 모든 환자와 우리는 "당신은 알고 있습니다, 우리는 매우 유감 스럽습니다. 우리는 암에 걸린 것 같아요."라고 말하면 정확도가 높다는 것을 의미합니다. 그들과 암은 암에 걸립니다.

7:38
우리가 계산하려고하는 두 번째 숫자는 리콜 (recall)이라고 부르며, 리콜은 모든 환자가 테스트 세트 또는 교차 유효성 검사 세트에서 말하면 실제로 데이터 세트의 모든 환자가 실제로 암,
7:52
우리가 정확하게 암을 발견했다고 감지 한 비율은 얼마입니까? 그래서 모든 환자가 암에 걸린 경우, 실제로 얼마나 많은 환자가 암에 걸렸는지 알고 있습니다. 치료가 필요하다고 생각한다고 말했습니다.
8:05
따라서 이것을 적어 두는 것은 양성 반응의 수, 실제 양성 반응의 수, 즉 암에 걸렸으며 정확하게 예측 한 사람의 수가 암을 가지고 있음을 의미합니다
8:20
우리는 이것을 받아 들여이를 실제적인 긍정의 수로 나눕니다.
8:31
이것이 암을 가진 모든 사람들의 실제 긍정적 인 숫자입니다. 우리가 어떤 부분을 직접 표시하고 알고 있는지, 치료를 보내십시오.
8:40
따라서이를 다른 형식으로 다시 작성하려면 분모는 알고있는 실제 긍정 수입니다. 여기서 첫 번째 열에있는 항목의 합계입니다.
8:50
그리고 다르게 쓰는 것이므로, 이것은 True positive의 수를 True positive  더하기  false negative의 수로 나눈 값입니다.
9:09
그리고 다시 한번, 높은 리콜을 갖는 것이 좋은 것입니다.

9:14
따라서 정밀도와 리콜을 계산하면 분류 자의 효율성을 더 잘 이해할 수 있습니다.
9:21
특히 y가 항상 0이라고 예측하는 학습 알고리즘을 사용하는 경우 아무도 암을 갖지 않는다고 예측하면이 분류 기준은 실제 긍정이 없으므로 리콜이 0이됩니다. 우리가 y를 항상 0으로 예측하는 분류자를 인식하는 빠른 방법은 아주 좋은 분류자가 아닙니다. 

(QUIZ)

그리고 더 일반적으로 우리가 클래스를 비뚤어지게 설정하는 경우에도 알고리즘이 "속임수"를 정렬 할 수없고 y를 0으로 예측하는 것과 같은 간단한 작업을 수행하여 매우 높은 정밀도와 매우 높은 회수율을 얻을 수 있습니다. 시간 또는 예측 y는 항상 1입니다. 따라서 정확도가 높거나 높은 리콜 분류자를 실제로 분류하는 것이 더 낳은 분류 자라는 것이 훨씬 더 확실합니다. 따라서 우리 알고리즘이 다음과 같은 사실을 실제로 이해할 수있는보다 직접적인 방법 인 유용한 평가 메트릭을 얻을 수 있습니다.
10:21
정밀도와 리콜의 정의에있어서 최종 정확도와 리콜을 정의하는 마지막 메모는 일반적으로보다 희귀 한 클래스가있는 경우 y가 1이라는 규칙을 사용합니다. 그래서 우리가 탐지하려고한다면. 암 같은 희귀 한 상황은 희소 한 상태 일 것입니다. 정밀도와 회상율은 y를 0으로 설정하는 대신 y를 1로 설정하여 정의 할 수 있습니다. 이는 희귀 한 클래스의 존재를 감지하기위한 것입니다. 그리고 정밀도와 리콜을 사용하면 클래스가 비뚤어져 있어도 알고리듬이 알고있는 "속임수를 쓰고"y를 항상 1로 예측하거나 y가 0과 같다고 예측할 수 없습니다 시간, 그리고 높은 정밀도와 리콜. 특히 분류 자의 정확도가 높고 회수율이 높으면 클래스가 비뚤어져 있어도 알고리즘이 제대로 작동해야한다고 확신합니다.
11:18
따라서 비뚤어진 클래스의 문제에 대해 정밀도 리콜은 학습 알고리즘이 수행되는 방식에 대한보다 직접적인 통찰력을 제공하며 클래스가 매우 비뚤어 질 때 분류 오류 또는 분류 정확도를 보는 것보다 학습 알고리즘을 평가하는 데 훨씬 좋은 방법입니다 .
